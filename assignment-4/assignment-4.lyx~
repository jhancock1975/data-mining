#LyX 1.6.7 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{fancyhdr}% http://ctan.org/pkg/fancyhdr
\fancyhead{}% Clear all headers
%\fancyfoot{}% Clear all footers
\fancyhead[C]{John Hancock}% Place "John Hancock" in Center of header
\renewcommand{\headrulewidth}{0pt}% Remove header rule
%\renewcommand{\footrulewidth}{0pt}% Remove footer rule
\pagestyle{fancy}% Set page style to "fancy"
\end_preamble
\use_default_options true
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family rmdefault
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize 12
\spacing double
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
Assignment 4: Feature Selection II.
\end_layout

\begin_layout Standard
John Hancock
\end_layout

\begin_layout Standard
Florida Atlantic University
\end_layout

\begin_layout Standard
Advanced Data Mining and Machine Learning CAP-6778
\end_layout

\begin_layout Standard
jhancoc4@fau.edu
\end_layout

\begin_layout Section*
Summary 
\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Section*
Methodology
\end_layout

\begin_layout Standard
For this work we run two Java programs 
\begin_inset Foot
status open

\begin_layout Plain Layout
the program for generating result data and storing it to a database is at
 
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

https://github.com/jhancock1975/data-mining-assignment-2/blob/master/cap-6778/src
/main/java/edu/fau/weka/Assignment4.java
\end_layout

\end_inset

 and the program for generating the gnuplot graphs is at 
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

https://github.com/jhancock1975/data-mining-assignment-2/blob/master/cap-6778/src
/main/java/edu/fau/weka/Assign4Reports.java
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
All of the source code that produces the results we report on in this work
 is available at https://github.com/jhancock1975/data-mining-assignment-2/tree/ma
ster/cap-6778.
\end_layout

\begin_layout Standard
The first program we wrote, Assignment4.java uses the Weka Java API to construct
 classifers and then iterate over combinations of classifiers and input
 data.
 
\end_layout

\begin_layout Standard
The classifiers Assignment4.java creates are: Naive Bayes (NB), 5-Nearest
 Neighbors (5NN), and J48 (C4.5) Decision Tree (J48).
 We use default settings for all classifiers, with the exception of setting
 the number of neighbers to 5 for the nearest neighbors classifier.
\end_layout

\begin_layout Standard
The dataset we use for this work is Lymphoma96x4026.arff.
 
\end_layout

\begin_layout Standard
The dataset has two classes, ACL and nonACL.
\end_layout

\begin_layout Standard
The Assignment 1 requirements document states, 
\begin_inset Quotes eld
\end_inset

Type I (False Positive): a nonACL module is classified as ACL.
\begin_inset Quotes erd
\end_inset

 Hence, ACL must be the positive class, because this statement says that
 something is classified as positive and it is classified in the ACL class.
 Since ACL must be the positive class, nonACL must be the negative class.
\end_layout

\begin_layout Standard
We us the dataset as-is as input for all three classifiers.
 In addition we apply one of the 6 feature selection techniques to the data
 to use a subset of the features in the dataset as input to the Naive Bayes
 classifier and the 5-Nearest Neigbors classifier.
\end_layout

\begin_layout Standard
The 6 feature selection techniques we use for this work are: Information
 Gain (IG), Gain Ratio (GR), Chi-Squared (CS), ReliefF (RF), ReliefF Weighted
 (RFW), and Symmetric Uncertainty (SU).
 For an overview of the functioning of these filter-based feature ranking
 techniques, please see part III.
 Methodolgy, section C.
 Feature Ranking Techniques of 
\begin_inset CommandInset citation
LatexCommand cite
key "key-20"

\end_inset

.
\end_layout

\begin_layout Standard
For each feature selection technique we set the number of features retained
 using the values 5, 6, 7, 8, 9, 10, 20, 50, 100, 200.
\end_layout

\begin_layout Standard
As Assignment4.java runs it stores classification results for each combination
 of dataset and classifier in a database.
 Due to the requirements in Assignment 4, we store the classifier's false
 positive rate (FPR), false negative rate (FNR), positive class area under
 receiver operating characteristic curve (pAUC), negative class AUC (nAUC),
 and weighted average AUC (wAUC).
 In addition we store a list of the features each feature selection technique
 retains for the dataset.
\end_layout

\begin_layout Standard
We run a second program, Assign4Reports.java to process the data stored in
 the database to generate graphics in the results below.
\end_layout

\begin_layout Standard
To answer other questions given in Assignment 4, we run queries on the data
 that Assignment4.java stores.
\end_layout

\begin_layout Standard
For all classifications we run, we use 10-fold cross validation.
\end_layout

\begin_layout Standard
To summarize the size of the experiments, we run 
\begin_inset Formula $2\times6\times10=120$
\end_inset

 combinations of classifiers, feature selection techniques , and number
 of features retained using 10-fold cross validation, plus one 10-fold cross
 validation each of the NB, 5NN, and J-48 classifiers using the full dataset
 as input, for a total of 123 sets of classification results.
\end_layout

\begin_layout Section*
Results
\end_layout

\begin_layout Subsection*
Patterns
\end_layout

\begin_layout Standard
Assignment 4 has the following requirement, 
\begin_inset Quotes eld
\end_inset


\series bold
discover patterns in terms of FPR, FNR, and AUC as the number of features
 retained changes.
 Report on these patterns...
\series default

\begin_inset Quotes erd
\end_inset

 The way we find patterns is to plot FPR, FNR, and AUC versus the number
 of features changes.
 
\end_layout

\begin_layout Standard
We review the plots and find the following patterns:
\end_layout

\begin_layout Itemize
For the 5NN classifier, the false negative rate tends to drop steeply when
 the number of features reaches is about 20, and decrease more slowly for
 larger numbers of features.
\end_layout

\begin_layout Itemize
For the 5NN classifier, the false positive rate rate tends to reach a minimum
 with around 20 features, and then stay flat or increase slow for larger
 numbers of features.
\end_layout

\begin_layout Itemize
For the 5NN classifier, all three AUC values that Weka collects always overlap.
 Furthermore, the pattern we see is that AUC values attain a maximum at
 20 to 100 features and vary slightly for larger number of features.
\end_layout

\begin_layout Itemize
For the NB classifier, we generally see the false negative error rate drop
 to a minimum at 20 features, and remain at this minimum for higher numbers
 of features.
\end_layout

\begin_layout Itemize
For the NB classifier, the false positive rates dip to minimum around the
 20 feature level, and rise steadily after that.
\end_layout

\begin_layout Itemize
For the NB classifier, AUC values do not always overlap.
 However, we see that generally, AUC values attain a local maximum around
 20 features.
 For higher numbers of features, sometimes the AUC values increase slowly
 after attaining the local maximum, and sometimes they decrease slowly.
\end_layout

\begin_layout Standard
The subsections below contain graphs for combinations of classifier and
 feature selection technique.
\end_layout

\begin_layout Subsubsection*
5NN with CS Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/5NN-with-CS/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 1
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-5NN-with-CS/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 2
\end_layout

\begin_layout Subsubsection*
5NN with GR Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/5NN-with-GR/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 3
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-5NN-with-GR/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 4
\end_layout

\begin_layout Subsubsection*
5NN with IG Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/5NN-with-IG/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 5
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-5NN-with-IG/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 6
\end_layout

\begin_layout Subsubsection*
5NN with RF Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/5NN-with-RF/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 7
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-5NN-with-RF/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 8
\end_layout

\begin_layout Subsubsection*
5NN with RFW Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/5NN-with-RFW/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 9
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-5NN-with-RFW/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 10
\end_layout

\begin_layout Subsubsection*
5NN with SU Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/5NN-with-SU/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 11
\end_layout

\begin_layout Paragraph*
AUC
\begin_inset Graphics
	filename java-output/AUC-5NN-with-SU/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 12
\end_layout

\begin_layout Subsubsection*
NB with CS Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/NB-with-CS/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 13
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-NB-with-CS/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 14
\end_layout

\begin_layout Subsubsection*
NB with GR Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/NB-with-GR/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 15
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-NB-with-GR/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 16
\end_layout

\begin_layout Subsubsection*
NB with IG Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/NB-with-IG/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 17
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-NB-with-IG/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 18
\end_layout

\begin_layout Subsubsection*
NB with RF Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/NB-with-RF/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 19
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-NB-with-RF/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 20
\end_layout

\begin_layout Subsubsection*
NB with RFW Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/NB-with-RFW/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 21
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-NB-with-RFW/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 22
\end_layout

\begin_layout Subsubsection*
NB with SU Attribute Selection
\end_layout

\begin_layout Paragraph*
Error Rates
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/NB-with-SU/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 23
\end_layout

\begin_layout Paragraph*
AUC
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename java-output/AUC-NB-with-SU/gnuplot.gplt.ps

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Figure 24
\end_layout

\begin_layout Subsection*
Optimal Number of Features in Terms of AUC
\end_layout

\begin_layout Standard
Assignment 4 requires us to report on AUC data in the following manner:
\end_layout

\begin_layout Standard
\begin_inset Quotes eld
\end_inset

...including the optimal number of features in terms of AUC, the evidence that
 led you to conclude this, and the resulting performance (in terms of FPR,
 FNR, and AUC) when this number is used.
 Besure to include the performance of the classifiers on the full set of
 attributes for comparison.
 In addition, discuss how these changes are influenced by the choice of
 classifier and ranker.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
We must make a note about AUC values Weka collects when it runs a classification.
 Weka collects 3 AUC values in classification results.
 One AUC value is associated with the positive class (ACL for the Lymphoma96x402
6.arff dataset, we refer to as pAUC), one with the negative class (nonACL,
 we refer to as nAUC), and a weighted average (we refer to as wAUC).
 For any of our results involving the 5NN classifier, all 3 AUC values are
 equal.
 However, for the NB classifier, results are not always equal.
 Therefore we may obtain a different optimal number of features depending
 on which AUC value we are interested in.
 We present results for all 3 AUC values.
\end_layout

\begin_layout Standard
We query our database of results to meet this requirement.
 For the results in this section, and sections below where we mention that
 we wrote queries to obtain results, we invite the reader to peruse queries
 in our source code repository under 
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

https://github.com/jhancock1975/data-mining-assignment-2/tree/master/cap-6778/src
/main/resources/sql
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Our first query results give the maximum pAUC value per combination of classifie
r and ranker.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|l|l|l|l|l|l|}
\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Classifier & FS Technique & Num.
 Features & pAUC & FPR & FNR & Figure 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & RFW & 20 & 0.977963 & 0.0136986 & 0.26087 & 10 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & SU & 20 & 0.977367 & 0.109589 & 0.0434783 & 24 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & CS & 20 & 0.976772 & 0.0547945 & 0.0434783 & 14 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & GR & 20 & 0.972603 & 0.0547945 & 0.0869565 &  16 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & CS & 20 & 0.972007 & 0.0136986 & 0.304348 & 2 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & IG & 20 & 0.966051 & 0.0958904 & 0.0434783 & 18 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & SU & 100 & 0.961584 & 0.0684932 & 0.130435 & 12 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & IG & 7 & 0.957117 & 0.0410959 & 0.304348 & 6 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & RF & 20 & 0.94461 & 0 & 0.521739 & 8 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & GR & 200 & 0.936569 & 0.0547945 & 0.173913 & 4 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & RFW & 200 & 0.931805 & 0.123288 & 0.0869565 & 22 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & RF & 200 & 0.928231 & 0.219178 & 0.0869565 & 20 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & No feature selection & 4026 & 0.882073 & 0.109589 & 0.391304 & (N/A)
 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & No feature selection & 4026 & 0.84455 & 0.178082 & 0.26087 & (N/A) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

J48 & Embedded feature selection & 4026 & 0.776951 & 0.0958904 & 0.391304 
 & (N/A) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Table 1: AUC values associated with positive (ACL) class by classifier and
 feature selection (FS) technique.
 The figure column indicates which figure in this document the reader may
 to refer to see the data in the associated row in graphical form.
 N/A stands for, 
\begin_inset Quotes eld
\end_inset

not available.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
The results are sorted by pAUC in descending order, so the overall highest
 pAUC value is in the first row, and so on.
 
\end_layout

\begin_layout Standard
We make some points about results in about results in Table 1:
\end_layout

\begin_layout Itemize
For the 5NN classifier and IG feature selection, figure 6 shows the maximum
 AUC value is attained twice, once for 7 features, and once for 40.
 We report 7 as the optimal number of features as it is our understanding
 that the data mining community prefers models with smaller feature sets
 over models with larger feature sets.
 We decide optimal feature numbers for other tie values similarly.
\end_layout

\begin_layout Itemize
For the 5NN classifier with GR feature selection, the maximum pAUC value
 is associated with 200 features selected, which is the maximum number of
 features selected in our experiments.
 However, we also see that using no feature selection technique, the pAUC
 value is lower.
 Therefore there must be a point at which adding features to the 5NN classifier
 GR feature selection technique comination begins to negatively impact classifie
r results as we see for other classifier and feature selection technique
 combinations.
 Also, we would like to point out that the slope of the pAUC curve for 5NN
 with GR in figure 4 diminishes for number of features equal to 50 and above.
\end_layout

\begin_layout Itemize
NB classifier with RF feature selection and NB classifier with RFW feature
 selection we see that the number of features associated with the highest
 pAUC value is 200.
 However the respective plots in Figures 20 and 22 and the pAUC value for
 NB classifier with no feature selection technique are similar to what we
 stated in the point above regarding 5NN classifier with GR feature selection.
\end_layout

\begin_layout Standard
The table below is similar to Table 1, but we alter our query to search
 for maximum nAUC values in order to generate it.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|l|l|l|l|l|l|}
\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Classifier & FS Technique & Num.
 Features & nAUC & FPR & FNR & Figure 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & SU & 100 & 0.978559 & 0.123288 & 0.0434783 & 24 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & RFW & 20 & 0.977963 & 0.0136986 & 0.26087 & 10 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & CS & 20 & 0.976772 & 0.0547945 & 0.0434783 & 14 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & GR & 100 & 0.976176 & 0.109589 & 0.0434783 & 16 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & IG & 100 & 0.973794 & 0.109589 & 0.0434783 & 18 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & CS & 20 & 0.972007 & 0.0136986 & 0.304348 & 2 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & SU & 100 & 0.961584 & 0.0684932 & 0.130435 & 12 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & IG & 7 & 0.957117 & 0.0410959 & 0.304348 & 6 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & RF & 20 & 0.94461 & 0 & 0.521739 & 8 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & GR & 200 & 0.936569 & 0.0547945 & 0.173913 & 4 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & RFW & 200 & 0.926147 & 0.123288 & 0.0869565 & 22 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & RF & 200 & 0.921977 & 0.219178 & 0.0869565 & 20 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & No feature selection & 4026 & 0.882073 & 0.109589 & 0.391304 & (N/A)
 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & No feature selection & 4026 & 0.82698 & 0.178082 & 0.26087 & (N/A) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

J48 & Embedded feature selection & 4026 & 0.780524 & 0.0958904 & 0.391304 &
 (N/A) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Table 2: AUC values associated with negative (nonACL) class by classifier
 and feature selection (FS) technique.
 The figure column indicates which figure in this document the reader may
 to refer to see the data in the associated row in graphical form.
 N/A stands for, 
\begin_inset Quotes eld
\end_inset

not available.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
We notice the following for Table 2:
\end_layout

\begin_layout Itemize
For the NB classifiers and GR, IG, and SU feature selection techniques,
 the number of features increases from 20 to 100.
\end_layout

\begin_layout Itemize
The positions of NB classifiers and their feature selection techniques in
 Table 2 differ from their postions in Table 1 since pAUC values can be
 different from nAUC values.
\end_layout

\begin_layout Standard
The next table presents results for the weighted AUC value we recorded for
 our experiments.
 It is generated in a manner similar to Tables 1 and 2.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|l|l|l|l|l|l|}
\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Classifier & FS Technique & Num.
 Features & wAUC & FPR & FNR & Figure 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & RFW & 20 & 0.977963 & 0.0136986 & 0.26087 & 10 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & SU & 20 & 0.977367 & 0.109589 & 0.0434783 & 24 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & CS & 20 & 0.976772 & 0.0547945 & 0.0434783 & 14 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & GR & 20 & 0.972603 & 0.0547945 & 0.0869565 & 16 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & CS & 20 & 0.972007 & 0.0136986 & 0.304348 & 2 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & IG & 50 & 0.966107 & 0.136986 & 0.0434783 & 18 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & SU & 100 & 0.961584 & 0.0684932 & 0.130435 & 12 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & IG & 7 & 0.957117 & 0.0410959 & 0.304348 & 6 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & RF & 20 & 0.94461 & 0 & 0.521739 & 8 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & GR & 200 & 0.936569 & 0.0547945 & 0.173913 & 4 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & RFW & 200 & 0.930449 & 0.123288 & 0.0869565 & 22 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & RF & 200 & 0.926733 & 0.219178 & 0.0869565 & 20 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

5NN & No feature selection & 4026 & 0.882073 & 0.109589 & 0.391304 & (N/A)
 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NB & No feature selection & 4026 & 0.840341 & 0.178082 & 0.26087 & (N/A) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

J48 & Embedded feature selection & 4026 & 0.777807 & 0.0958904 & 0.391304 &
 (N/A) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\shape italic
Table 3: weighted average AUC values associated by classifier and feature
 selection (FS) technique.
 The figure column indicates which figure in this document the reader may
 to refer to see the data in the associated row in graphical form.
 N/A stands for, 
\begin_inset Quotes eld
\end_inset

not available.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
We notice that the number of features for optimum wAUC value for NB classifier
 with IG, SU, or GR feature selection techniques is again different from
 the optimum number of features for nAUC value in Table 2, changing to 50,
 20, and 20, respectively.
\end_layout

\begin_layout Subsection*
Comparisons with J48
\end_layout

\begin_layout Standard
for each classifier, pick ranker with best auc value (again may be 3 altertnativ
es) for 6 features retained, compare with j48 6 features, calculate consistency
 index
\end_layout

\begin_layout Standard
look at over-all results maybe some classifier+ranker combinations do worse
 than j48, some do better
\end_layout

\begin_layout Section*
Conclusions 
\end_layout

\begin_layout Section*
Future Research
\end_layout

\begin_layout Section*
references notes - delete
\end_layout

\begin_layout Standard
key-2 is auc,
\end_layout

\begin_layout Standard
key-22 is naive bayes,
\end_layout

\begin_layout Standard
key-24 is nearest neighbors, 
\end_layout

\begin_layout Standard
key-20 is information gain and chi squared,
\end_layout

\begin_layout Standard
key-26 will be for consistency index
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-2"

\end_inset

I.
 Witten and E.
 Frank, Data Mining (second edition).
 San Francisco: Elsevier, 2005, ch.
 5 p.169 fig.
 5.2.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-22"

\end_inset

I.
 Witten and E.
 Frank, Data Mining (second edition).
 San Francisco: Elsevier, 2005, ch.
 4 pp.89-91
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-24"

\end_inset

I.
 Witten and E.
 Frank, Data Mining (second edition).
 San Francisco: Elsevier, 2005, ch.
 4 pp.128-136
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-20"

\end_inset

J.
 R.
 Wald, T.
 M.
 Khoshgoftaar, A.
 Abu Shanab, 
\begin_inset Quotes eld
\end_inset

The Effect of Measurement Approach and Noise Level on Gene Selection Stability,
\begin_inset Quotes erd
\end_inset

 in IEEE International Conference on Bioinformatics and Biomedicine (BIBM),
 Philadelphia, PA, 2012.
 doi: 10.1109/BIBM.2012.6392713
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-26"

\end_inset

T.
 M.
 Khoshgoftaar, Overcoming Big Data Challenges.Presented in lecture, Florida
 Atlantic University 2014 October 2.
\end_layout

\end_body
\end_document
